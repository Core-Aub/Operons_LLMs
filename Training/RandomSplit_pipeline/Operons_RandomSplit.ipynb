{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JeeiqrnZhd1",
    "outputId": "db58337b-6dfc-4b1c-d1cc-1e3dc0259b19"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.24.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (1.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (0.24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2026.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.24.0->datasets) (0.24.0)\n",
      "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.24.0->datasets) (8.3.1)\n",
      "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.24.0->datasets) (13.9.4)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.24.0->datasets) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.24.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.24.0->datasets) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.24.0->datasets) (0.1.2)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.6\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, precision_recall_curve, auc, confusion_matrix\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ],
   "metadata": {
    "id": "fN4kbXLdZq8j"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import huggingface_hub\n",
    "huggingface_hub.login()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141,
     "referenced_widgets": [
      "9692fad906d74bb5917a8bfba3752446",
      "f5f4dfc64bab4171a6170991b06b99ac",
      "0278ee6cfd1c48b8b614363b479bf1b3",
      "8b8464c6a1b34525acebdef7ca0eb6d8",
      "1ad8616d176442169ea9b6a162581b0b",
      "df29aa108c2741cca9ece159e6b2ce3e",
      "d5cc9ab898a14bf5ac9d4831e8b7901d",
      "7316127da27a47fa894b14f47692a281",
      "d257dc70ece1456eaa83b1ef3ae19526",
      "75afd93cf3e142cfabefd4885094eb0c",
      "5b5394c3017840159f931559b195cd85",
      "e9efa3d955aa4499890166ecf25d0128",
      "0119db2849a64b1ca2b4abc66ea8a493",
      "e917a7f2d1b44bbf90305b130307f628",
      "0ec89e4b34a244ab93885453479d736c",
      "5c1ecf30e8d74691a5adc99aebda1387",
      "564a3cde8632407db8a43bafcfb12a3a",
      "a907511792b44063843096de0e4a4a15",
      "2b809645e29040558783d3ab74710a38",
      "4368e3eadace4baeb398fffc40ad0db6"
     ]
    },
    "id": "xolN1StlZtm5",
    "outputId": "56972af6-83c6-4f5a-b566-37f302c4244f"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9692fad906d74bb5917a8bfba3752446"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import set_seed\n",
    "SEED = 0\n",
    "set_seed(SEED)\n",
    "\n",
    "# Deterministic behavior (may slow training)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ],
   "metadata": {
    "id": "dD9oF0EiZvRh"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_split_from_serialized(path, valid_size = 0.1, test_size = 0.1, seed=0):\n",
    "    \"\"\"\n",
    "    Loads a serialized CSV file and splits it into training, validation, and test sets.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the serialized CSV file (must include 'text', 'label', etc.).\n",
    "        valid_size (float): Proportion of the dataset to include in the validation split.\n",
    "        test_size (float): Proportion of the dataset to include in the test split.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        DatasetDict with 'train', 'validation', and 'test' datasets.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    if \"text\" not in df.columns or \"label\" not in df.columns:\n",
    "        raise ValueError(\"CSV file must contain 'text' and 'label' columns.\")\n",
    "\n",
    "    # First split: separate test set from the rest\n",
    "    train_val_df, test_df = train_test_split(df, test_size=test_size, stratify=df[\"label\"], random_state=seed, shuffle=True)\n",
    "\n",
    "    # Calculate the proportion of validation set relative to the combined train+val set\n",
    "    # For example, if valid_size=0.1 and train_size=0.8, then valid_ratio_in_train_val = 0.1 / (0.8 + 0.1) = 0.1 / 0.9 = 1/9\n",
    "    valid_ratio_in_train_val = valid_size / (1.0 - test_size)\n",
    "\n",
    "    # Second split: separate validation set from the training set\n",
    "    train_df, valid_df = train_test_split(train_val_df, test_size=valid_ratio_in_train_val, stratify=train_val_df[\"label\"], random_state=seed, shuffle=True)\n",
    "\n",
    "    return DatasetDict({\n",
    "        \"train\": Dataset.from_pandas(train_df.reset_index(drop=True)),\n",
    "        \"validation\": Dataset.from_pandas(valid_df.reset_index(drop=True)),\n",
    "        \"test\": Dataset.from_pandas(test_df.reset_index(drop=True))\n",
    "    })"
   ],
   "metadata": {
    "id": "NlERPXPQjKuw"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "   predictions, labels = eval_pred\n",
    "   #predictions = np.argmax(predictions[0], axis=1)\n",
    "   predictions = np.argmax(predictions, axis=-1) # for roberta?\n",
    "\n",
    "   return accuracy.compute(predictions=predictions, references=labels)"
   ],
   "metadata": {
    "id": "kg9C9JUTZ5ja",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c73444b6be1043c2a40896f20ccbb1bd",
      "8370696533bb4225943fd8a44af587a1",
      "7ea9ace0129648cb91767dc9045de070",
      "6c8434a104ac4011a3b9b0b9ae552d75",
      "334e1e591cec417097d892ec61015ac2",
      "93adeabf7964411ba543c8742a555c4f",
      "100e9d3db272463eb3994e611f23007f",
      "eb4464d31f7245159dc019db2cf54d67",
      "040ecbc857e14eb29ac4bc9403f39f19",
      "0e7c88a563a940a58a35122e78b75999",
      "924dbe2b00ae481d85155fd5870b7230"
     ]
    },
    "outputId": "3e4bf03a-b028-4bfc-b6a3-afe0aa8d8992"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c73444b6be1043c2a40896f20ccbb1bd"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training The Model via 80/20 Random Split Strategie"
   ],
   "metadata": {
    "id": "9BHnExUdjSEf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Choosing the DataSet"
   ],
   "metadata": {
    "id": "oNO9wvzzjc42"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data_path = \"/content/roundrobin_conservation.csv\""
   ],
   "metadata": {
    "id": "CA4UCuQhjQro"
   },
   "execution_count": 87,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Choosing the LLM"
   ],
   "metadata": {
    "id": "uGJ_wKyojfhX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_id = \"roberta-base\""
   ],
   "metadata": {
    "id": "yEi_8ZLRjjdc"
   },
   "execution_count": 88,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split the data"
   ],
   "metadata": {
    "id": "Zf2s-huujmTu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "imdb = load_split_from_serialized(data_path)"
   ],
   "metadata": {
    "id": "t4O9gn_2jrYn"
   },
   "execution_count": 89,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(imdb)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M61zle5Sj12d",
    "outputId": "dd1046b1-a2c7-4697-8955-7e7c29bf077f"
   },
   "execution_count": 90,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['genome_id', 'gene1', 'gene2', 'text', 'label'],\n",
      "        num_rows: 6783\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['genome_id', 'gene1', 'gene2', 'text', 'label'],\n",
      "        num_rows: 848\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['genome_id', 'gene1', 'gene2', 'text', 'label'],\n",
      "        num_rows: 848\n",
      "    })\n",
      "})\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id,device_map = 'auto')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344,
     "referenced_widgets": [
      "1dfb752c2ef544a8a92d96baebf5723f",
      "71c2d59169344d388ad84bc5f4e4e3a8",
      "b04bed6ebaa44bb984ac6453eca3cfaf",
      "207e3d3a47aa4eb5adbf1f346f0eb06a",
      "45c703be338549d1a3e746e96c31cef7",
      "9cafbe9b70ea424cbdb0c79d48c49b25",
      "ea86e9468faa420c8d994fce46e81c9c",
      "27914f12aa1d4417bb6be9fb50277429",
      "bde349b47f00475f89435c333dc35262",
      "0c1cd6b1582f4a60ad69b345740b597b",
      "ee0547533f0442f79e4e52a4416a77d5"
     ]
    },
    "id": "QbB62zZmj6Dv",
    "outputId": "7710c115-82df-4f2e-e83a-586953a4a522"
   },
   "execution_count": 91,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/197 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1dfb752c2ef544a8a92d96baebf5723f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "RobertaForSequenceClassification LOAD REPORT from: roberta-base\n",
      "Key                             | Status     | \n",
      "--------------------------------+------------+-\n",
      "lm_head.layer_norm.bias         | UNEXPECTED | \n",
      "lm_head.dense.weight            | UNEXPECTED | \n",
      "lm_head.bias                    | UNEXPECTED | \n",
      "lm_head.layer_norm.weight       | UNEXPECTED | \n",
      "lm_head.dense.bias              | UNEXPECTED | \n",
      "roberta.embeddings.position_ids | UNEXPECTED | \n",
      "classifier.out_proj.bias        | MISSING    | \n",
      "classifier.dense.bias           | MISSING    | \n",
      "classifier.dense.weight         | MISSING    | \n",
      "classifier.out_proj.weight      | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    model.to(device)"
   ],
   "metadata": {
    "id": "BqVUP8SAZxdq"
   },
   "execution_count": 92,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_function(examples):\n",
    "   return tokenizer(examples[\"text\"])"
   ],
   "metadata": {
    "id": "gUxbYpELkAi-"
   },
   "execution_count": 93,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_imdb = imdb.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "caf4abe1bb2343288fa9f21ce7e3f2db",
      "61afa46a576e41f1a8779956d24036c4",
      "37f3217e2e324e8cb94558ad1b7f33d2",
      "2c0f39a2b7e547d788845ef2ba3b5562",
      "8a8a0fb995c246d4af66ed1ca24c2d54",
      "2b411be34e624add85cbc09cabbe3d79",
      "1e7e2b5b4eb548679636bbe2f1f3070b",
      "d25f52153fd648eda19a764bb77cb93b",
      "457bc7a47aca4f16b6457df8f84b5108",
      "109216c0d16844f3ac784a3094b8a004",
      "2b33b71eb9b94cb78f273375accbfba2",
      "2d1f847633114f729856849be17559e1",
      "4d8ee0d3b42a4f4fb92099418ac63eeb",
      "54013d4b116e435cb2d20b361adc5a83",
      "a160d69158824300ab21420c69057648",
      "2bafae367a7a4399a22e53ab1a26724a",
      "def405e34a1c4afabe74bebb18d6bf1d",
      "992dd468144e46ae9a02395c6e2861d9",
      "d34cfb29ae7e4e8fb55f21097ab61ebc",
      "126697f63acf446b88e11ff9d497da43",
      "d58e0d97178841d08c4ff8120a8aeda3",
      "7d879d79726540beb2e7df10c086b87e",
      "ef04e9dba57c4462998e59f73755fa8a",
      "a4c641dc70ae46a9a7f9dd5b52d66174",
      "cae33a02e7754b669f27003e070f904d",
      "c6796352db7c48d08b452af3390ba5da",
      "a2afb62e9b5e4bd7a3cce04da3002fb6",
      "00901dbf66e34316abea3671e4e66503",
      "b131b815a59645288f883e00b203d9e7",
      "b3b23284424e4fa1b050b5384ecc4098",
      "8c44293abc124773ab3a5a883d30ef92",
      "04b7bce6faf6427a908db7b1c168378b",
      "25912458ae724e08919731745be6cbab"
     ]
    },
    "id": "YM8ej9kTkEp9",
    "outputId": "655a2ea5-a668-4168-e09d-b0a9d00655b3"
   },
   "execution_count": 94,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/6783 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "caf4abe1bb2343288fa9f21ce7e3f2db"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/848 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d1f847633114f729856849be17559e1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/848 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef04e9dba57c4462998e59f73755fa8a"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "   output_dir=\"operons_conservation\",\n",
    "   learning_rate=3e-5,\n",
    "   per_device_train_batch_size=32,\n",
    "   per_device_eval_batch_size=32,\n",
    "   num_train_epochs=10,\n",
    "   weight_decay=0.01, # 0001\n",
    "   lr_scheduler_type= \"linear\", # polynomial\n",
    "   seed=0,\n",
    "   data_seed=0,\n",
    "\n",
    "   load_best_model_at_end=True,\n",
    "   metric_for_best_model = \"accuracy\",\n",
    "   eval_strategy='epoch',\n",
    "   save_strategy='epoch'\n",
    ")"
   ],
   "metadata": {
    "id": "f4_Kvp9ckKP2"
   },
   "execution_count": 95,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, max_length= 2048)"
   ],
   "metadata": {
    "id": "5F510iJCkMom"
   },
   "execution_count": 96,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "   model = model,\n",
    "   args=training_args,\n",
    "   train_dataset=tokenized_imdb[\"train\"],\n",
    "   eval_dataset=tokenized_imdb[\"validation\"],\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics\n",
    ")"
   ],
   "metadata": {
    "id": "pi5_cx0jkPig"
   },
   "execution_count": 97,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ca495108f5b74c91bd6cc81bcb23b619",
      "396a12e9239641ac802fe3e98f2c98e8",
      "3b6da894132f46e6810a45dd860d15a4",
      "e0c93c453cc24ab1b0d1eb1e57312b06",
      "44f8778b778046d1b33eca82cdb21087",
      "9eec934983e34a9da3302815343a50d1",
      "0ddc99cb62a7483cb8d025e35d9cff03",
      "532cce61c9f84de797cd977b61bb6b26",
      "375d8dba4a2e4b1bbed593b4f12f2749",
      "44c38bfc2a044597b83afffe52622e5f",
      "5b8b6189bcd540a594af610cfb26cf5e",
      "c4f01d801ca149e9abbadb5a12c31b9e",
      "03fa61c5072f4553af86e2ac150eaf4f",
      "886670895a8e49b3ae5fb93fe84024da",
      "0333f91a682c434698dccf2e51b11ff8",
      "f86053b4ea874fdca3a1fe8275a3a7ef",
      "ad260027a1ad4bc689138438fe419761",
      "4934a887534a4ffb8b4070c72c710ed9",
      "9b63638012f442fd9e1568aa9e45ba91",
      "a943aca18c2c40ccab1e611216f045ad",
      "629acd58bc54475e99ca8982382e77f0",
      "1f7f306c4e3647abb7534e6e56165207",
      "e6e10ca3d639444ebfd3f06792edade4",
      "8108673926e8432d98e30efc720fc825",
      "2706177b399346c8b298c29175644902",
      "c8c1b604e2ff43739a52412031d05481",
      "fd5e56486ca24c9fbfb987e29a49cae3",
      "f1df08095f874284a085304a13325c4d",
      "31b4aed611034ed2b8e5ac0feb69b4d5",
      "bba83df5bda44f33aeacb9ab8e09dc5c",
      "753b469102964733a083be664c8d3b17",
      "134dc2657b35482c979faadd667985c3",
      "ca16ff133ec04c6da466bc375d5a3928",
      "d4e4dcd2f3e343369e397cb7006ee707",
      "e8ec7cd3409d4e00b87666a0d716f76c",
      "b2ffcc0df8224eb392240e20e0f0d7e0",
      "ba960b7b4f9e464491a9f80295cc732b",
      "fd66f12ef8654cfbb31f5441eed84cb1",
      "835f0099a2a749318511b3ae82ff3fd3",
      "4f1aa3d03c26406382ac3647365acf44",
      "89e57726d4fd420087d055007d65d00f",
      "5359c65c3ab64562b9a56e0ac77b86c1",
      "6a81ba51a9244dc1b6b69759c25edb28",
      "d229390701a34983ac74f0655b4bd9e3",
      "b602065738604d73918de72fb4ff409d",
      "c686ed9f1f1b4a12a3d83002ab778aff",
      "d890e4a2d33f428eaa6ee24a8531980c",
      "3c019a83335447ebb8b9cc521c4dd95a",
      "2af35a07eff24c13ac4b2875820f76fe",
      "36d03e9a0f8442609c78c4312f8416b2",
      "2f335da0bdcc44d394b428f362d77320",
      "1171286c1bec4779a7ba852d032ba225",
      "f49c8cc7ae0e4184b89cc72ba9478c58",
      "9eff7690569144bba1b77769bbbd747d",
      "de8e862e3e3a4819a9d2fc11768fe0f8",
      "53796b110ca7487d899435934babe682",
      "aacfa421bb5c4bfcb63977797414dc91",
      "5ee45d33f1d94c9d82c32b4b546ac4d3",
      "f262a49364f84ab489a20a2cfe6f76c9",
      "184bf5a1d5394ea29e5e3115aca55317",
      "b691b45ace534b3a9fd72fb8dd0b10cb",
      "ab0e5909a3a842188bd8f67af19dbf1e",
      "55e816b7885d4ff8990e6b12a3394113",
      "dc8fd715d4944698a508eba5ce04ccf5",
      "b180d114d79b4703a7bcbc504ffdb83d",
      "64a26e27b6ff481dbee23811bcefcb6b",
      "e7fdd93f174f48e08dd19dd231374880",
      "ad3bcb81e4484d989131080f3dedeefc",
      "88cd60a217584e3da4ce675266532955",
      "73ad5378d7c14338a63bf543ddf27ca4",
      "0848579ef70f47ce8381e9f9d2442a90",
      "409151bd45ad442888581c90d2e61a1f",
      "fffde6eac54048a896e00c645cb17338",
      "aa6f66b709f34d82b07e17c29b34c296",
      "d1b247dce1e24ef2a0680d4a1aca4ffb",
      "c36de335d93646679eb0979a70a81bdd",
      "32c9131a7030478eb51dd4c17c2c3043",
      "445a91cbf0534903947037a496869b2c",
      "6001aafb40324585a895abfcb3c16849",
      "90e716707883463f9f7f19fbe947e472",
      "5640e162812a49dcad43989c02a10b73",
      "5b641a08362d47eaa1c352a131896d08",
      "441a33d4b75f4a13934485ae44c60ac8",
      "b87bad4297614521add76a9cfe4f50f6",
      "6ceb4fa8e9ad401dbe0d864320dcc7aa",
      "822870c418bb4a018ed40fccd4e0294a",
      "087c7f7247cf4c2b987aba55c654d4ef",
      "cecc4ed2a3cf4bf7bbc8ae461a60dee2",
      "3a4d81515d6c4b8a9ee4d7eec4fbae47",
      "f85e44731fbf4c3ca01d8ae261578410",
      "96a1d4485b0643ccb5d503929b45f312",
      "a0f8ce0831544aae80ca84f2945d3a95",
      "1662f562125c4eb5ba466da2ed598003",
      "f5640afaa6a64ae892fcadc8559248f1",
      "359687cf4f6d42a8a4a34f0f919c06eb",
      "bed4a725df1e4e9cbde5126e303407d7",
      "5dcebf3681b24ba18a4f5257e2cdbea4",
      "a0bce944ddaf435f8add0f445357e8ff",
      "1dab5927fb5f4f4fba34d3aae8233a27",
      "3871e1bc48444703b3ad96826c129345",
      "a665807d74cd46d09555e4b90900a799",
      "49226c4440f94ec496c379d7cd8109ab",
      "fd5afacb231e4abd8a29b7ad5741f06c",
      "84ca0d700f30429a9fc0a0bd9bfebaf9",
      "828378e63d70450a80827b64d2c1edd1",
      "3ba3fe96ad3a4fa7a68bab6eb22c4516",
      "71e4b339e92045a09a80529510c45f13",
      "f34da6faf903431185ab48ef5855eb67",
      "27bedb98f9da4ae6941a2353f62f1852",
      "385c7bd1aefb40d982ac56e7eb39b6da"
     ]
    },
    "id": "NqoM7om3kXfd",
    "outputId": "250d3165-a853-4b93-faeb-4a940ad4c8e5"
   },
   "execution_count": 98,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2402: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2120' max='2120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2120/2120 03:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.414759</td>\n",
       "      <td>0.841981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.405361</td>\n",
       "      <td>0.826651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.416886</td>\n",
       "      <td>0.400673</td>\n",
       "      <td>0.837264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.416886</td>\n",
       "      <td>0.375383</td>\n",
       "      <td>0.838443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.361025</td>\n",
       "      <td>0.384605</td>\n",
       "      <td>0.840802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.361025</td>\n",
       "      <td>0.377693</td>\n",
       "      <td>0.836085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.361025</td>\n",
       "      <td>0.385706</td>\n",
       "      <td>0.833726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.345963</td>\n",
       "      <td>0.376215</td>\n",
       "      <td>0.834906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.345963</td>\n",
       "      <td>0.389154</td>\n",
       "      <td>0.833726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.327508</td>\n",
       "      <td>0.393638</td>\n",
       "      <td>0.834906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca495108f5b74c91bd6cc81bcb23b619"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2402: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4f01d801ca149e9abbadb5a12c31b9e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2402: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6e10ca3d639444ebfd3f06792edade4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2402: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4e4dcd2f3e343369e397cb7006ee707"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2402: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b602065738604d73918de72fb4ff409d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2402: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53796b110ca7487d899435934babe682"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2402: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e7fdd93f174f48e08dd19dd231374880"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2402: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "445a91cbf0534903947037a496869b2c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2402: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a4d81515d6c4b8a9ee4d7eec4fbae47"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2402: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3871e1bc48444703b3ad96826c129345"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['roberta.embeddings.LayerNorm.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias'].\n",
      "There were unexpected keys in the checkpoint model loaded: ['roberta.embeddings.LayerNorm.beta', 'roberta.embeddings.LayerNorm.gamma', 'roberta.encoder.layer.0.attention.output.LayerNorm.beta', 'roberta.encoder.layer.0.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.0.output.LayerNorm.beta', 'roberta.encoder.layer.0.output.LayerNorm.gamma', 'roberta.encoder.layer.1.attention.output.LayerNorm.beta', 'roberta.encoder.layer.1.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.1.output.LayerNorm.beta', 'roberta.encoder.layer.1.output.LayerNorm.gamma', 'roberta.encoder.layer.2.attention.output.LayerNorm.beta', 'roberta.encoder.layer.2.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.2.output.LayerNorm.beta', 'roberta.encoder.layer.2.output.LayerNorm.gamma', 'roberta.encoder.layer.3.attention.output.LayerNorm.beta', 'roberta.encoder.layer.3.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.3.output.LayerNorm.beta', 'roberta.encoder.layer.3.output.LayerNorm.gamma', 'roberta.encoder.layer.4.attention.output.LayerNorm.beta', 'roberta.encoder.layer.4.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.4.output.LayerNorm.beta', 'roberta.encoder.layer.4.output.LayerNorm.gamma', 'roberta.encoder.layer.5.attention.output.LayerNorm.beta', 'roberta.encoder.layer.5.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.5.output.LayerNorm.beta', 'roberta.encoder.layer.5.output.LayerNorm.gamma', 'roberta.encoder.layer.6.attention.output.LayerNorm.beta', 'roberta.encoder.layer.6.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.6.output.LayerNorm.beta', 'roberta.encoder.layer.6.output.LayerNorm.gamma', 'roberta.encoder.layer.7.attention.output.LayerNorm.beta', 'roberta.encoder.layer.7.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.7.output.LayerNorm.beta', 'roberta.encoder.layer.7.output.LayerNorm.gamma', 'roberta.encoder.layer.8.attention.output.LayerNorm.beta', 'roberta.encoder.layer.8.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.8.output.LayerNorm.beta', 'roberta.encoder.layer.8.output.LayerNorm.gamma', 'roberta.encoder.layer.9.attention.output.LayerNorm.beta', 'roberta.encoder.layer.9.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.9.output.LayerNorm.beta', 'roberta.encoder.layer.9.output.LayerNorm.gamma', 'roberta.encoder.layer.10.attention.output.LayerNorm.beta', 'roberta.encoder.layer.10.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.10.output.LayerNorm.beta', 'roberta.encoder.layer.10.output.LayerNorm.gamma', 'roberta.encoder.layer.11.attention.output.LayerNorm.beta', 'roberta.encoder.layer.11.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.11.output.LayerNorm.beta', 'roberta.encoder.layer.11.output.LayerNorm.gamma'].\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2120, training_loss=0.3605721239773732, metrics={'train_runtime': 215.6461, 'train_samples_per_second': 314.543, 'train_steps_per_second': 9.831, 'total_flos': 2237561164767720.0, 'train_loss': 0.3605721239773732, 'epoch': 10.0})"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "_-nFzLOekZ81",
    "outputId": "67f595be-ead9-4c83-d9ad-37d4044296bd"
   },
   "execution_count": 99,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2402: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4142387807369232,\n",
       " 'eval_accuracy': 0.8419811320754716,\n",
       " 'eval_runtime': 0.8986,\n",
       " 'eval_samples_per_second': 943.693,\n",
       " 'eval_steps_per_second': 30.047,\n",
       " 'epoch': 10.0}"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.push_to_hub()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229,
     "referenced_widgets": [
      "3ee5c47750774a52af27c7151318df67",
      "81a464aa810748ccbbb6f62b92310174",
      "e46c2393f0c94fb48f53f33ba0ec137e",
      "9e01e2ea1b1348fca5637cc279f6b5d2",
      "38e98d1b942b4e4690359dc3d757ffb6",
      "1ac9019c87724659a494c1dd8c7e807a",
      "65ff92792ba7482496b61ff8b084884b",
      "dd9f4a26291d40df83103f8fd1c7b5e7",
      "8936763698414978a07245c8d1cb543b",
      "3a847f3ebf6b461b883cc93d575fa7b3",
      "b799ee7f5b3e43f197e914a3d880e562",
      "219b6b65045a4bf68e9f9aa6e0e0908f",
      "20fc0712916d4619b023b8d392d3944b",
      "9447c0389b144507996dda06f33c3660",
      "8608d1b67ea247d6bac3070e441a1977",
      "ee9b86969dfe45ca87481c1f0971665b",
      "c954a1c27a154972a9effdace1eaf6e5",
      "91a30df672674f7e95969446d448835c",
      "4cfaf14dc1ac449abd04fcde164ed90f",
      "8acbfbde7fc64b18a10878a5948b35b3",
      "53d2ca935ab246da80a65b86e92142a1",
      "fa01af7a3def49de8cde50cc9179146b",
      "39cd8f4c2e294c749ca53ca12efd609e",
      "642e478995304802b4090bbd7724b6c5",
      "a5f20de710bb4c0a9265fb2230455d08",
      "e37da9aa5e9f40f4a5d5c1e5845c7510",
      "5726e67c809446d488901b18eef77c94",
      "0c3c23ea7ad14da89ce588606dfa85b1",
      "961c5d07919a476fa28cd7ad382da0e7",
      "4ecf2ffa74fa426d8067771ec91fd54a",
      "15c9b59472e34459a80d7246fc7769fe",
      "ccd6dfcff19c498fa4b8157b0a16ec13",
      "76b5fb23d280409d9b92330226a30e75",
      "62f96fff0bc2490287c0f79e591afe27",
      "3d61cc9381014ee1b4b7170f83714472",
      "7e2c5f42f901472594912658910ecfd6",
      "860654801e714132937a24f22b58db94",
      "d9b365e7c6ad48d8993be9766f30fe81",
      "44c54765b2d944c9a7f99373d1197e92",
      "7982be01b72249158a4949784d8919ba",
      "06674cc711864ec499255a104efae5ee",
      "30ab41dbd88b4fbfa63eb98c7dbc1489",
      "db10fd9e0b604483a499d004c14a5a4e",
      "e57ff82de911443d835f32110580badc",
      "ad5039e6b2304f2292c7a7f43b12ace6",
      "35784e91703a4168a89a9c259e9af7bd",
      "8a8eb7c474d440f4b15920e45ada68c2",
      "eb0077ba97654e68bae01080a8514c56",
      "c113e423bc3d4bffaedaa0a7da20ea8a",
      "0dc90178d5f3435698007e1bae596f39",
      "905f8f85a48d4abe9620126fe666ad0c",
      "afd11d4e36104bb0a8abbf1133831bc0",
      "1a2b76ee354f42a895e9709c7595efe2",
      "9be8e12c3e7f4d86acce4c2605be3209",
      "34019c6b4755475eb44a0e49ed659971"
     ]
    },
    "id": "c5xyvTXMkcD3",
    "outputId": "d7cf3a84-04bf-45c0-8340-02d7fb1a4587"
   },
   "execution_count": 100,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ee5c47750774a52af27c7151318df67"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "219b6b65045a4bf68e9f9aa6e0e0908f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39cd8f4c2e294c749ca53ca12efd609e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  ...rvation/model.safetensors:   0%|          |  556kB /  499MB            "
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62f96fff0bc2490287c0f79e591afe27"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  ...rvation/training_args.bin:   2%|1         |  98.0B / 5.20kB            "
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad5039e6b2304f2292c7a7f43b12ace6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/bif02/operons_conservation/commit/a14faf6ae74432fae22b551835154f232d9577bc', commit_message='End of training', commit_description='', oid='a14faf6ae74432fae22b551835154f232d9577bc', pr_url=None, repo_url=RepoUrl('https://huggingface.co/bif02/operons_conservation', endpoint='https://huggingface.co', repo_type='model', repo_id='bif02/operons_conservation'), pr_revision=None, pr_num=None)"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 100
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing on 10% of the dataset"
   ],
   "metadata": {
    "id": "k02Cq3kJkmW0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Reload accuracy metric to ensure it's not a float from previous runs\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "ppredictions_ = trainer.predict(test_dataset=tokenized_imdb[\"test\"])\n",
    "llabels_ = ppredictions_.label_ids\n",
    "# Unpack logits from predictions\n",
    "llogits_ = ppredictions_.predictions[0] if isinstance(ppredictions_.predictions, tuple) else ppredictions_.predictions\n",
    "ppreds_ = np.argmax(llogits_, axis=-1)\n",
    "\n",
    "# Sensitivity\n",
    "sensitivity_ = recall_score(llabels_, ppreds_)\n",
    "\n",
    "# Specificity\n",
    "tn, fp, fn, tp = confusion_matrix(llabels_, ppreds_).ravel()\n",
    "specificity_ = tn / (tn + fp)\n",
    "\n",
    "# Precision\n",
    "precision_f = tp/(tp+fp)\n",
    "\n",
    "# PR_AUC\n",
    "precision_, recall_, thresholds_ = precision_recall_curve(llabels_, ppreds_)\n",
    "\n",
    "# 2. Calculate the area under those points\n",
    "pr_auc_ = auc(recall_, precision_)\n",
    "calculated_accuracy_ = (tp+tn)/(tp+fp+tn+fn) # Renamed to avoid collision with global 'accuracy' object\n",
    "f1_score_ = (2*sensitivity_*precision_f)/(sensitivity_+precision_f)\n",
    "print(\"Sensitivity:\", sensitivity_)\n",
    "print(\"Specificity:\", specificity_)\n",
    "print(\"accuracy:\", calculated_accuracy_) # Print the renamed variable\n",
    "print(\"f1-score:\", f1_score_)\n",
    "print(\"PR_AUC:\",pr_auc_ )"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "id": "j_sCJrkekjFW",
    "outputId": "aafb48df-e88a-4f12-bd09-54dd05a987b1"
   },
   "execution_count": 101,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2402: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sensitivity: 0.8259860788863109\n",
      "Specificity: 0.8633093525179856\n",
      "accuracy: 0.8443396226415094\n",
      "f1-score: 0.8436018957345973\n",
      "PR_AUC: 0.8882074736338449\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Plot Confusion Matrix\n",
    "cm = confusion_matrix(llabels_, ppreds_)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "JfIIICmclBts",
    "outputId": "b46df42a-49cf-47b8-912b-94a51663a2fb"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  }
 ]
}
